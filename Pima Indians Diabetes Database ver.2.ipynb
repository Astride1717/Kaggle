{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/uciml/pima-indians-diabetes-database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ver2. : SVC 모델사용(매개변수 조정에 GridSearch사용, 교차검증을 사용한 GridSearchCV 사용 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#피마 인디언 당뇨병 예측 - 머신러닝 예측 모델을 수립하고, 평가 지표를 적용\n",
    "#1. 데이터를 로딩한 후 분포와 데이터를 확인해 보세요.\n",
    "import pandas as pd\n",
    "pima = pd.read_csv('../data/diabetes.csv')\n",
    "pima.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2. 당뇨병에 걸린 사람과 아닌 사람의 수 확인\n",
    "pima['Outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x121300f0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAPcElEQVR4nO3de6xlZXnH8e8PRkSryGVGijODY+rYilGRTigtf9SCMUBbh1oxGpUpTjJNSlsvTVtqm9qbibYqFTXESVEGQlWKF9CYtmREjRfUgyIXqWWkFiZDmUEQtRZb8Okf+z0vm5kzsMVZZx9mfz/Jzl7rWe9e85zJyfllXfa7UlVIkgRwwLQbkCQtHYaCJKkzFCRJnaEgSeoMBUlSt2zaDfwkli9fXmvWrJl2G5L0qHLNNdfcWVUrFtr2qA6FNWvWMDc3N+02JOlRJcl/7m2bp48kSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKkqRu0FBI8q0k1ye5Nslcqx2e5MokN7f3w1o9Sc5Lsi3JdUmOG7I3SdKeFuNI4Veq6tiqWtfWzwG2VtVaYGtbBzgVWNtem4DzF6E3SdKYaZw+Wg9sactbgNPH6hfVyNXAoUmOmkJ/kjSzhv5GcwH/mqSA91TVZuDIqrodoKpuT/LkNnYlcNvYZ7e32u3jO0yyidGRBEcfffRP3ODP/+FFP/E+tP+55u/OnHYL0lQMHQonVtWO9of/yiT/9hBjs0Btj8fCtWDZDLBu3TofGydJ+9Cgp4+qakd73wl8BDgeuGP+tFB739mGbwdWj318FbBjyP4kSQ82WCgk+akkT5xfBl4I3ABcAWxowzYAl7flK4Az211IJwD3zJ9mkiQtjiFPHx0JfCTJ/L/zj1X1z0m+DFyaZCNwK3BGG/8J4DRgG/AD4KwBe5MkLWCwUKiqW4DnLlD/NnDyAvUCzh6qH0nSw/MbzZKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKkqTOUJAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1A0eCkkOTPLVJB9v609L8sUkNyf5YJKDWv2xbX1b275m6N4kSQ+2GEcKrwFuGlt/C3BuVa0F7gY2tvpG4O6qejpwbhsnSVpEg4ZCklXArwL/0NYDnARc1oZsAU5vy+vbOm37yW28JGmRDH2k8PfAHwE/autHAN+pqvva+nZgZVteCdwG0Lbf08Y/SJJNSeaSzO3atWvI3iVp5gwWCkl+DdhZVdeMlxcYWhNse6BQtbmq1lXVuhUrVuyDTiVJ85YNuO8TgRclOQ04GDiE0ZHDoUmWtaOBVcCONn47sBrYnmQZ8CTgrgH7kyTtZrAjhar6k6paVVVrgJcBn6yqVwBXAS9pwzYAl7flK9o6bfsnq2qPIwVJ0nCm8T2FPwZen2Qbo2sGF7T6BcARrf564Jwp9CZJM23I00ddVX0K+FRbvgU4foEx9wJnLEY/kqSF+Y1mSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKkqTOUJAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqBguFJAcn+VKSryW5MclftvrTknwxyc1JPpjkoFZ/bFvf1ravGao3SdLChjxS+CFwUlU9FzgWOCXJCcBbgHOrai1wN7Cxjd8I3F1VTwfObeMkSYtosFCoke+31ce0VwEnAZe1+hbg9La8vq3Ttp+cJEP1J0na06DXFJIcmORaYCdwJfBN4DtVdV8bsh1Y2ZZXArcBtO33AEcM2Z8k6cEGDYWqur+qjgVWAccDz1xoWHtf6Kigdi8k2ZRkLsncrl279l2zkqTFufuoqr4DfAo4ATg0ybK2aRWwoy1vB1YDtO1PAu5aYF+bq2pdVa1bsWLF0K1L0kwZ8u6jFUkObcuPA14A3ARcBbykDdsAXN6Wr2jrtO2frKo9jhQkScNZ9vBDHrGjgC1JDmQUPpdW1ceTfB34QJK/Ab4KXNDGXwBcnGQboyOElw3YmyRpAROFQpKtVXXyw9XGVdV1wPMWqN/C6PrC7vV7gTMm6UeSNIyHDIUkBwOPB5YnOYwHLgYfAjxl4N4kSYvs4Y4Ufht4LaMAuIYHQuG7wLsH7EuSNAUPGQpV9Q7gHUl+r6reuUg9SZKmZKJrClX1ziS/BKwZ/0xVXTRQX5KkKZj0QvPFwM8A1wL3t3IBhoIk7UcmvSV1HXCM3xuQpP3bpF9euwH46SEbkSRN36RHCsuBryf5EqMpsQGoqhcN0pUkaSomDYW/GLIJSXu69a+ePe0WtAQd/efXD7r/Se8++vSgXUiSloRJ7z76Hg9MY30Qowfm/HdVHTJUY5KkxTfpkcITx9eTnM4C8xdJkh7dHtHU2VX1UUaP1ZQk7UcmPX304rHVAxh9b8HvLEjSfmbSu49+fWz5PuBbwPp93o0kaaomvaZw1tCNSJKmb6JrCklWJflIkp1J7kjyoSSrhm5OkrS4Jr3Q/D5Gz1B+CrAS+FirSZL2I5OGwoqqel9V3ddeFwIrBuxLkjQFk4bCnUlemeTA9nol8O0hG5MkLb5JQ+HVwEuB/wJuB14CePFZkvYzk96S+tfAhqq6GyDJ4cBbGYWFJGk/MemRwnPmAwGgqu4CnjdMS5KkaZk0FA5Ictj8SjtSmPQoQ5L0KDHpH/a3AZ9Pchmj6S1eCrxpsK4kSVMx6TeaL0oyx2gSvAAvrqqvD9qZJGnRTXwKqIWAQSBJ+7FHNHW2JGn/ZChIkjpDQZLUGQqSpM5QkCR1hoIkqRssFJKsTnJVkpuS3JjkNa1+eJIrk9zc3g9r9SQ5L8m2JNclOW6o3iRJCxvySOE+4A+q6pnACcDZSY4BzgG2VtVaYGtbBzgVWNtem4DzB+xNkrSAwUKhqm6vqq+05e8BNzF6att6YEsbtgU4vS2vBy6qkauBQ5McNVR/kqQ9Lco1hSRrGM2q+kXgyKq6HUbBATy5DVsJ3Db2se2ttvu+NiWZSzK3a9euIduWpJkzeCgkeQLwIeC1VfXdhxq6QK32KFRtrqp1VbVuxQqfCCpJ+9KgoZDkMYwC4ZKq+nAr3zF/Wqi972z17cDqsY+vAnYM2Z8k6cGGvPsowAXATVX19rFNVwAb2vIG4PKx+pntLqQTgHvmTzNJkhbHkA/KORF4FXB9kmtb7Q3Am4FLk2wEbgXOaNs+AZwGbAN+gM+AlqRFN1goVNVnWfg6AcDJC4wv4Oyh+pEkPTy/0SxJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKkqTOUJAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSd1goZDkvUl2JrlhrHZ4kiuT3NzeD2v1JDkvybYk1yU5bqi+JEl7N+SRwoXAKbvVzgG2VtVaYGtbBzgVWNtem4DzB+xLkrQXg4VCVX0GuGu38npgS1veApw+Vr+oRq4GDk1y1FC9SZIWttjXFI6sqtsB2vuTW30lcNvYuO2ttockm5LMJZnbtWvXoM1K0qxZKheas0CtFhpYVZural1VrVuxYsXAbUnSbFnsULhj/rRQe9/Z6tuB1WPjVgE7Frk3SZp5ix0KVwAb2vIG4PKx+pntLqQTgHvmTzNJkhbPsqF2nOT9wPOB5Um2A28E3gxcmmQjcCtwRhv+CeA0YBvwA+CsofqSJO3dYKFQVS/fy6aTFxhbwNlD9SJJmsxSudAsSVoCDAVJUmcoSJI6Q0GS1BkKkqTOUJAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKkqTOUJAkdYaCJKkzFCRJnaEgSeqWVCgkOSXJN5JsS3LOtPuRpFmzZEIhyYHAu4FTgWOAlyc5ZrpdSdJsWTKhABwPbKuqW6rqf4EPAOun3JMkzZRl025gzErgtrH17cAv7D4oySZgU1v9fpJvLEJvs2I5cOe0m1gK8tYN025BD+bv5rw3Zl/s5al727CUQmGhn7T2KFRtBjYP387sSTJXVeum3Ye0O383F89SOn20HVg9tr4K2DGlXiRpJi2lUPgysDbJ05IcBLwMuGLKPUnSTFkyp4+q6r4kvwv8C3Ag8N6qunHKbc0aT8tpqfJ3c5Gkao/T9pKkGbWUTh9JkqbMUJAkdYaCnF5ES1aS9ybZmeSGafcyKwyFGef0IlriLgROmXYTs8RQkNOLaMmqqs8Ad027j1liKGih6UVWTqkXSVNmKGii6UUkzQZDQU4vIqkzFOT0IpI6Q2HGVdV9wPz0IjcBlzq9iJaKJO8HvgD8bJLtSTZOu6f9ndNcSJI6jxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKmnlJViW5PMnNSb6Z5B3tOxsP9Zk3LFZ/0mIyFDTTkgT4MPDRqloLPAN4AvCmh/mooaD9kqGgWXcScG9VvQ+gqu4HXge8OsnvJHnX/MAkH0/y/CRvBh6X5Nokl7RtZya5LsnXklzcak9NsrXVtyY5utUvTHJ+kquS3JLkl9tzA25KcuHYv/fCJF9I8pUk/5TkCYv2v6KZZSho1j0LuGa8UFXfBW4Fli30gao6B/ifqjq2ql6R5FnAnwInVdVzgde0oe8CLqqq5wCXAOeN7eYwRoH0OuBjwLmtl2cnOTbJcuDPgBdU1XHAHPD6ffEDSw9lwV96aYaEhWeF3Vt9IScBl1XVnQBVNT///y8CL27LFwN/O/aZj1VVJbkeuKOqrgdIciOwhtHEhMcAnxud4eIgRtM9SIMyFDTrbgR+c7yQ5BBGM8few4OPpg/eyz4mDZDxMT9s7z8aW55fXwbcD1xZVS+fYL/SPuPpI826rcDjk5wJ/fGkb2P0GMhbgGOTHJBkNaOn1M37vySPGdvHS5Mc0fZxeKt/ntGsswCvAD77Y/R1NXBikqe3fT4+yTN+3B9O+nEZCpppNZoR8jeAM5LcDPw7cC+ju4s+B/wHcD3wVuArYx/dDFyX5JI2q+ybgE8n+Rrw9jbm94GzklwHvIoHrjVM0tcu4LeA97fPXw383CP9OaVJOUuqJKnzSEGS1BkKkqTOUJAkdYaCJKkzFCRJnaEgSeoMBUlS9/9V5qx0XSyBzAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(pima['Outcome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregnancies                 0\n",
      "Glucose                     0\n",
      "BloodPressure               0\n",
      "SkinThickness               0\n",
      "Insulin                     0\n",
      "BMI                         0\n",
      "DiabetesPedigreeFunction    0\n",
      "Age                         0\n",
      "Outcome                     0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      "Pregnancies                 768 non-null int64\n",
      "Glucose                     768 non-null int64\n",
      "BloodPressure               768 non-null int64\n",
      "SkinThickness               768 non-null int64\n",
      "Insulin                     768 non-null int64\n",
      "BMI                         768 non-null float64\n",
      "DiabetesPedigreeFunction    768 non-null float64\n",
      "Age                         768 non-null int64\n",
      "Outcome                     768 non-null int64\n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#3. feature의 타입과 Null 개수 확인\n",
    "print(pima.isnull().sum())\n",
    "print(pima.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_g = pima[\"SkinThickness\"] == 0\n",
    "pima.loc[bad_g, \"SkinThickness\"] = None\n",
    "sum(pima['SkinThickness']==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_g = pima[\"BloodPressure\"] == 0\n",
    "pima.loc[bad_g, \"BloodPressure\"] = None\n",
    "sum(pima['BloodPressure']==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_g = pima[\"Insulin\"] == 0\n",
    "pima.loc[bad_g, \"Insulin\"] = None\n",
    "sum(pima['Insulin']==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0인 값을 결측치로 바꾼 후 중간값으로 대체\n",
    "pima.fillna(pima.mean(), inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "pima.target = pima['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "pima.data = pima.drop('Outcome', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>35.00000</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>29.00000</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>23.00000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>35.00000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>32.00000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>115</td>\n",
       "      <td>72.405184</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.134</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>45.00000</td>\n",
       "      <td>543.000000</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>125</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>37.6</td>\n",
       "      <td>0.191</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>168</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.537</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>139</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>27.1</td>\n",
       "      <td>1.441</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>23.00000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.398</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>166</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>19.00000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>25.8</td>\n",
       "      <td>0.587</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>72.405184</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.484</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>47.00000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>45.8</td>\n",
       "      <td>0.551</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>107</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.254</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>38.00000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.183</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>34.6</td>\n",
       "      <td>0.529</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>126</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>41.00000</td>\n",
       "      <td>235.000000</td>\n",
       "      <td>39.3</td>\n",
       "      <td>0.704</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8</td>\n",
       "      <td>99</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>35.4</td>\n",
       "      <td>0.388</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7</td>\n",
       "      <td>196</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>39.8</td>\n",
       "      <td>0.451</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9</td>\n",
       "      <td>119</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>35.00000</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.263</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>11</td>\n",
       "      <td>143</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>33.00000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>36.6</td>\n",
       "      <td>0.254</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10</td>\n",
       "      <td>125</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>26.00000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>31.1</td>\n",
       "      <td>0.205</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7</td>\n",
       "      <td>147</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>39.4</td>\n",
       "      <td>0.257</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>23.2</td>\n",
       "      <td>0.487</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>13</td>\n",
       "      <td>145</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>19.00000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>22.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>117</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>34.1</td>\n",
       "      <td>0.337</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>17.00000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>36.6</td>\n",
       "      <td>0.453</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>39.5</td>\n",
       "      <td>0.293</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>11</td>\n",
       "      <td>120</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>37.00000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>42.3</td>\n",
       "      <td>0.785</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>3</td>\n",
       "      <td>102</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>30.8</td>\n",
       "      <td>0.400</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0.219</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>9</td>\n",
       "      <td>140</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>32.7</td>\n",
       "      <td>0.734</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>13</td>\n",
       "      <td>153</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>37.00000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>40.6</td>\n",
       "      <td>1.174</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>33.00000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.488</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>41.00000</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>49.3</td>\n",
       "      <td>0.358</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>41.00000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>46.3</td>\n",
       "      <td>1.096</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>3</td>\n",
       "      <td>187</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>22.00000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>36.4</td>\n",
       "      <td>0.408</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>6</td>\n",
       "      <td>162</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>24.3</td>\n",
       "      <td>0.178</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>4</td>\n",
       "      <td>136</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>31.2</td>\n",
       "      <td>1.182</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>39.00000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.261</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>3</td>\n",
       "      <td>108</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>24.00000</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.223</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>44.00000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.222</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>8</td>\n",
       "      <td>154</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>32.00000</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>32.4</td>\n",
       "      <td>0.443</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>39.00000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>36.5</td>\n",
       "      <td>1.057</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>7</td>\n",
       "      <td>137</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>41.00000</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.391</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>36.3</td>\n",
       "      <td>0.258</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>37.5</td>\n",
       "      <td>0.197</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>6</td>\n",
       "      <td>190</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>35.5</td>\n",
       "      <td>0.278</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>26.00000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0.766</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>9</td>\n",
       "      <td>170</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>31.00000</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.403</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>9</td>\n",
       "      <td>89</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.142</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>48.00000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>27.00000</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.00000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>31.00000</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness     Insulin   BMI  \\\n",
       "0              6      148           72.0       35.00000  155.548223  33.6   \n",
       "1              1       85           66.0       29.00000  155.548223  26.6   \n",
       "2              8      183           64.0       29.15342  155.548223  23.3   \n",
       "3              1       89           66.0       23.00000   94.000000  28.1   \n",
       "4              0      137           40.0       35.00000  168.000000  43.1   \n",
       "..           ...      ...            ...            ...         ...   ...   \n",
       "763           10      101           76.0       48.00000  180.000000  32.9   \n",
       "764            2      122           70.0       27.00000  155.548223  36.8   \n",
       "765            5      121           72.0       23.00000  112.000000  26.2   \n",
       "766            1      126           60.0       29.15342  155.548223  30.1   \n",
       "767            1       93           70.0       31.00000  155.548223  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  \n",
       "0                       0.627   50  \n",
       "1                       0.351   31  \n",
       "2                       0.672   32  \n",
       "3                       0.167   21  \n",
       "4                       2.288   33  \n",
       "..                        ...  ...  \n",
       "763                     0.171   63  \n",
       "764                     0.340   27  \n",
       "765                     0.245   30  \n",
       "766                     0.349   47  \n",
       "767                     0.315   23  \n",
       "\n",
       "[768 rows x 8 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트의 크기: 576 테스트 세트의 크기: 192\n",
      "최고 점수:0.750\n",
      "최적 매개변수 {'C': 1, 'gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "#SVC모델 사용 -> 그리드서치로 최적의 매개변수 찾기\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(pima.data, pima.target, random_state = 0)\n",
    "print(\"훈련 세트의 크기: {} 테스트 세트의 크기: {}\".format(X_train.shape[0], X_test.shape[0]))\n",
    "best_score = 0\n",
    "\n",
    "for gamma  in [0.001, 0.01, 0.01, 1, 10, 100] :\n",
    "    for C in [0.001, 0.01, 0.01, 1, 10, 100] :\n",
    "        svm = SVC(gamma = gamma, C=C)\n",
    "        svm.fit(X_train, y_train)\n",
    "        score = svm.score(X_test, y_test)\n",
    "        if score > best_score : \n",
    "            best_score = score\n",
    "            best_parameters = {'C': C, 'gamma': gamma}\n",
    "            \n",
    "print(\"최고 점수:{:.3f}\".format(best_score))\n",
    "print(\"최적 매개변수\",best_parameters)\n",
    "\n",
    "#최적의 매개변수를 사용했음에도 ver.1의 로지스틱 회귀보다 점수가 0.01감소 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#StandardScaler 사용 후 다시 SVC 적용해보기\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 세트 점수: 0.792\n",
      "최적 매개변수: {'C': 1, 'gamma': 0.01}\n",
      "최고 교차 검증 점수: 0.759\n"
     ]
    }
   ],
   "source": [
    "#교차 검증을 사용한 그리드 서치(교차 검증 성능이 가장 좋은 매개변수로 전체 훈련 데이터셋에 대해 새로운 모델을 만든다)\n",
    "param_grid = {'C' :[0.001, 0.01, 0.01, 1, 10, 100] ,\n",
    "             'gamma' : [0.001, 0.01, 0.01, 1, 10, 100]}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv = 5,return_train_score = True)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"테스트 세트 점수: {:.3f}\".format(grid_search.score(X_test_scaled, y_test)))\n",
    "print(\"최적 매개변수:\", grid_search.best_params_)\n",
    "print(\"최고 교차 검증 점수: {:.3f}\".format(grid_search.best_score_))  #best_score_ =교차 검증의 평균 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최고 성능 모델:\n",
      " SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print(\"최고 성능 모델:\\n\", grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>0.00740051</td>\n",
       "      <td>0.00460029</td>\n",
       "      <td>0.00460029</td>\n",
       "      <td>0.00480037</td>\n",
       "      <td>0.00580034</td>\n",
       "      <td>0.0126007</td>\n",
       "      <td>0.00480042</td>\n",
       "      <td>0.00480042</td>\n",
       "      <td>0.00480022</td>\n",
       "      <td>0.00580034</td>\n",
       "      <td>0.00980053</td>\n",
       "      <td>0.0132008</td>\n",
       "      <td>0.00460033</td>\n",
       "      <td>0.00480027</td>\n",
       "      <td>0.00500021</td>\n",
       "      <td>0.00580039</td>\n",
       "      <td>0.0102006</td>\n",
       "      <td>0.0132007</td>\n",
       "      <td>0.00480032</td>\n",
       "      <td>0.00480037</td>\n",
       "      <td>0.00400023</td>\n",
       "      <td>0.00720043</td>\n",
       "      <td>0.0118007</td>\n",
       "      <td>0.0144008</td>\n",
       "      <td>0.00480018</td>\n",
       "      <td>0.00480042</td>\n",
       "      <td>0.00480032</td>\n",
       "      <td>0.00860062</td>\n",
       "      <td>0.0154008</td>\n",
       "      <td>0.0158009</td>\n",
       "      <td>0.00500021</td>\n",
       "      <td>0.00800047</td>\n",
       "      <td>0.00800042</td>\n",
       "      <td>0.00800037</td>\n",
       "      <td>0.0146009</td>\n",
       "      <td>0.016401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.00215411</td>\n",
       "      <td>0.000489882</td>\n",
       "      <td>0.000489882</td>\n",
       "      <td>0.00040009</td>\n",
       "      <td>0.000399995</td>\n",
       "      <td>0.000489824</td>\n",
       "      <td>0.000400114</td>\n",
       "      <td>0.000400114</td>\n",
       "      <td>0.000400019</td>\n",
       "      <td>0.000399995</td>\n",
       "      <td>0.000399995</td>\n",
       "      <td>0.000399923</td>\n",
       "      <td>0.000489921</td>\n",
       "      <td>0.000400043</td>\n",
       "      <td>1.16801e-07</td>\n",
       "      <td>0.000400019</td>\n",
       "      <td>0.000399995</td>\n",
       "      <td>0.000399971</td>\n",
       "      <td>0.000399947</td>\n",
       "      <td>0.00040009</td>\n",
       "      <td>1.78416e-07</td>\n",
       "      <td>0.00040009</td>\n",
       "      <td>0.000400162</td>\n",
       "      <td>0.00048994</td>\n",
       "      <td>0.000399995</td>\n",
       "      <td>0.000400114</td>\n",
       "      <td>0.000400066</td>\n",
       "      <td>0.000489901</td>\n",
       "      <td>0.000489921</td>\n",
       "      <td>0.000399923</td>\n",
       "      <td>1.16801e-07</td>\n",
       "      <td>0.00063241</td>\n",
       "      <td>0.00063241</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00048994</td>\n",
       "      <td>0.00101995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.00139995</td>\n",
       "      <td>0.00100002</td>\n",
       "      <td>0.00100002</td>\n",
       "      <td>0.00119996</td>\n",
       "      <td>0.00120001</td>\n",
       "      <td>0.00300007</td>\n",
       "      <td>0.000999928</td>\n",
       "      <td>0.00120001</td>\n",
       "      <td>0.00120015</td>\n",
       "      <td>0.00120006</td>\n",
       "      <td>0.00140009</td>\n",
       "      <td>0.00280004</td>\n",
       "      <td>0.000999975</td>\n",
       "      <td>0.00120006</td>\n",
       "      <td>0.00100017</td>\n",
       "      <td>0.00140009</td>\n",
       "      <td>0.00140004</td>\n",
       "      <td>0.0032002</td>\n",
       "      <td>0.00140009</td>\n",
       "      <td>0.000999975</td>\n",
       "      <td>0.00100002</td>\n",
       "      <td>0.0012002</td>\n",
       "      <td>0.00160007</td>\n",
       "      <td>0.00300035</td>\n",
       "      <td>0.00100012</td>\n",
       "      <td>0.00100002</td>\n",
       "      <td>0.00100002</td>\n",
       "      <td>0.00140004</td>\n",
       "      <td>0.0012001</td>\n",
       "      <td>0.00300016</td>\n",
       "      <td>0.00100012</td>\n",
       "      <td>0.000800037</td>\n",
       "      <td>0.00100007</td>\n",
       "      <td>0.00180016</td>\n",
       "      <td>0.00180006</td>\n",
       "      <td>0.00300002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.000800037</td>\n",
       "      <td>1.16801e-07</td>\n",
       "      <td>1.16801e-07</td>\n",
       "      <td>0.000400066</td>\n",
       "      <td>0.000399923</td>\n",
       "      <td>9.53674e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000400043</td>\n",
       "      <td>0.000399971</td>\n",
       "      <td>0.000400019</td>\n",
       "      <td>0.000489901</td>\n",
       "      <td>0.000399971</td>\n",
       "      <td>9.53674e-08</td>\n",
       "      <td>0.000400019</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000489999</td>\n",
       "      <td>0.00048994</td>\n",
       "      <td>0.000399876</td>\n",
       "      <td>0.000489901</td>\n",
       "      <td>9.53674e-08</td>\n",
       "      <td>1.16801e-07</td>\n",
       "      <td>0.000399947</td>\n",
       "      <td>0.000489921</td>\n",
       "      <td>1.90735e-07</td>\n",
       "      <td>1.78416e-07</td>\n",
       "      <td>1.16801e-07</td>\n",
       "      <td>1.90735e-07</td>\n",
       "      <td>0.00048994</td>\n",
       "      <td>0.000399995</td>\n",
       "      <td>1.90735e-07</td>\n",
       "      <td>9.53674e-08</td>\n",
       "      <td>0.000400019</td>\n",
       "      <td>1.16801e-07</td>\n",
       "      <td>0.000400114</td>\n",
       "      <td>0.000400066</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_C</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_gamma</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'C': 0.001, 'gamma': 0.001}</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.01}</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.01}</td>\n",
       "      <td>{'C': 0.001, 'gamma': 1}</td>\n",
       "      <td>{'C': 0.001, 'gamma': 10}</td>\n",
       "      <td>{'C': 0.001, 'gamma': 100}</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.001}</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.01}</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.01}</td>\n",
       "      <td>{'C': 0.01, 'gamma': 1}</td>\n",
       "      <td>{'C': 0.01, 'gamma': 10}</td>\n",
       "      <td>{'C': 0.01, 'gamma': 100}</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.001}</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.01}</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.01}</td>\n",
       "      <td>{'C': 0.01, 'gamma': 1}</td>\n",
       "      <td>{'C': 0.01, 'gamma': 10}</td>\n",
       "      <td>{'C': 0.01, 'gamma': 100}</td>\n",
       "      <td>{'C': 1, 'gamma': 0.001}</td>\n",
       "      <td>{'C': 1, 'gamma': 0.01}</td>\n",
       "      <td>{'C': 1, 'gamma': 0.01}</td>\n",
       "      <td>{'C': 1, 'gamma': 1}</td>\n",
       "      <td>{'C': 1, 'gamma': 10}</td>\n",
       "      <td>{'C': 1, 'gamma': 100}</td>\n",
       "      <td>{'C': 10, 'gamma': 0.001}</td>\n",
       "      <td>{'C': 10, 'gamma': 0.01}</td>\n",
       "      <td>{'C': 10, 'gamma': 0.01}</td>\n",
       "      <td>{'C': 10, 'gamma': 1}</td>\n",
       "      <td>{'C': 10, 'gamma': 10}</td>\n",
       "      <td>{'C': 10, 'gamma': 100}</td>\n",
       "      <td>{'C': 100, 'gamma': 0.001}</td>\n",
       "      <td>{'C': 100, 'gamma': 0.01}</td>\n",
       "      <td>{'C': 100, 'gamma': 0.01}</td>\n",
       "      <td>{'C': 100, 'gamma': 1}</td>\n",
       "      <td>{'C': 100, 'gamma': 10}</td>\n",
       "      <td>{'C': 100, 'gamma': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>0.637931</td>\n",
       "      <td>0.637931</td>\n",
       "      <td>0.637931</td>\n",
       "      <td>0.637931</td>\n",
       "      <td>0.637931</td>\n",
       "      <td>0.637931</td>\n",
       "      <td>0.637931</td>\n",
       "      <td>0.637931</td>\n",
       "      <td>0.637931</td>\n",
       "      <td>0.637931</td>\n",
       "      <td>0.637931</td>\n",
       "      <td>0.637931</td>\n",
       "      <td>0.637931</td>\n",
       "      <td>0.637931</td>\n",
       "      <td>0.637931</td>\n",
       "      <td>0.637931</td>\n",
       "      <td>0.637931</td>\n",
       "      <td>0.637931</td>\n",
       "      <td>0.637931</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.62069</td>\n",
       "      <td>0.637931</td>\n",
       "      <td>0.637931</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.62069</td>\n",
       "      <td>0.637931</td>\n",
       "      <td>0.637931</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.62069</td>\n",
       "      <td>0.637931</td>\n",
       "      <td>0.637931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.773913</td>\n",
       "      <td>0.773913</td>\n",
       "      <td>0.713043</td>\n",
       "      <td>0.634783</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.791304</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.713043</td>\n",
       "      <td>0.634783</td>\n",
       "      <td>0.643478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.765217</td>\n",
       "      <td>0.765217</td>\n",
       "      <td>0.678261</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.756522</td>\n",
       "      <td>0.721739</td>\n",
       "      <td>0.721739</td>\n",
       "      <td>0.686957</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.73913</td>\n",
       "      <td>0.756522</td>\n",
       "      <td>0.756522</td>\n",
       "      <td>0.686957</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.686957</td>\n",
       "      <td>0.686957</td>\n",
       "      <td>0.634783</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.686957</td>\n",
       "      <td>0.686957</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.66087</td>\n",
       "      <td>0.66087</td>\n",
       "      <td>0.591304</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.669565</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.791304</td>\n",
       "      <td>0.791304</td>\n",
       "      <td>0.669565</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.765217</td>\n",
       "      <td>0.765217</td>\n",
       "      <td>0.669565</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>0.642361</td>\n",
       "      <td>0.642361</td>\n",
       "      <td>0.642361</td>\n",
       "      <td>0.642361</td>\n",
       "      <td>0.642361</td>\n",
       "      <td>0.642361</td>\n",
       "      <td>0.642361</td>\n",
       "      <td>0.642361</td>\n",
       "      <td>0.642361</td>\n",
       "      <td>0.642361</td>\n",
       "      <td>0.642361</td>\n",
       "      <td>0.642361</td>\n",
       "      <td>0.642361</td>\n",
       "      <td>0.642361</td>\n",
       "      <td>0.642361</td>\n",
       "      <td>0.642361</td>\n",
       "      <td>0.642361</td>\n",
       "      <td>0.642361</td>\n",
       "      <td>0.642361</td>\n",
       "      <td>0.758681</td>\n",
       "      <td>0.758681</td>\n",
       "      <td>0.659722</td>\n",
       "      <td>0.642361</td>\n",
       "      <td>0.642361</td>\n",
       "      <td>0.758681</td>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.744792</td>\n",
       "      <td>0.659722</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>0.642361</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.746528</td>\n",
       "      <td>0.746528</td>\n",
       "      <td>0.65625</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>0.642361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.00222465</td>\n",
       "      <td>0.00222465</td>\n",
       "      <td>0.00222465</td>\n",
       "      <td>0.00222465</td>\n",
       "      <td>0.00222465</td>\n",
       "      <td>0.00222465</td>\n",
       "      <td>0.00222465</td>\n",
       "      <td>0.00222465</td>\n",
       "      <td>0.00222465</td>\n",
       "      <td>0.00222465</td>\n",
       "      <td>0.00222465</td>\n",
       "      <td>0.00222465</td>\n",
       "      <td>0.00222465</td>\n",
       "      <td>0.00222465</td>\n",
       "      <td>0.00222465</td>\n",
       "      <td>0.00222465</td>\n",
       "      <td>0.00222465</td>\n",
       "      <td>0.00222465</td>\n",
       "      <td>0.00222465</td>\n",
       "      <td>0.0407987</td>\n",
       "      <td>0.0407987</td>\n",
       "      <td>0.0278695</td>\n",
       "      <td>0.00222465</td>\n",
       "      <td>0.00222465</td>\n",
       "      <td>0.0377225</td>\n",
       "      <td>0.0371569</td>\n",
       "      <td>0.0371569</td>\n",
       "      <td>0.0395188</td>\n",
       "      <td>0.00362665</td>\n",
       "      <td>0.00222465</td>\n",
       "      <td>0.0376801</td>\n",
       "      <td>0.0461291</td>\n",
       "      <td>0.0461291</td>\n",
       "      <td>0.0443217</td>\n",
       "      <td>0.00362665</td>\n",
       "      <td>0.00222465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>35</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>35</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.643478</td>\n",
       "      <td>0.641304</td>\n",
       "      <td>0.769565</td>\n",
       "      <td>0.769565</td>\n",
       "      <td>0.982609</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.767391</td>\n",
       "      <td>0.793478</td>\n",
       "      <td>0.793478</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.769565</td>\n",
       "      <td>0.819565</td>\n",
       "      <td>0.819565</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.644252</td>\n",
       "      <td>0.774403</td>\n",
       "      <td>0.774403</td>\n",
       "      <td>0.969631</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.765727</td>\n",
       "      <td>0.791757</td>\n",
       "      <td>0.791757</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.772234</td>\n",
       "      <td>0.800434</td>\n",
       "      <td>0.800434</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.774403</td>\n",
       "      <td>0.774403</td>\n",
       "      <td>0.960954</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.772234</td>\n",
       "      <td>0.789588</td>\n",
       "      <td>0.789588</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.774403</td>\n",
       "      <td>0.819957</td>\n",
       "      <td>0.819957</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_score</th>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.652928</td>\n",
       "      <td>0.780911</td>\n",
       "      <td>0.780911</td>\n",
       "      <td>0.967462</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.780911</td>\n",
       "      <td>0.81128</td>\n",
       "      <td>0.81128</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.791757</td>\n",
       "      <td>0.826464</td>\n",
       "      <td>0.826464</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_score</th>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.642082</td>\n",
       "      <td>0.639913</td>\n",
       "      <td>0.754881</td>\n",
       "      <td>0.754881</td>\n",
       "      <td>0.97397</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.759219</td>\n",
       "      <td>0.776573</td>\n",
       "      <td>0.776573</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.763557</td>\n",
       "      <td>0.815618</td>\n",
       "      <td>0.815618</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>0.642362</td>\n",
       "      <td>0.642362</td>\n",
       "      <td>0.642362</td>\n",
       "      <td>0.642362</td>\n",
       "      <td>0.642362</td>\n",
       "      <td>0.642362</td>\n",
       "      <td>0.642362</td>\n",
       "      <td>0.642362</td>\n",
       "      <td>0.642362</td>\n",
       "      <td>0.642362</td>\n",
       "      <td>0.642362</td>\n",
       "      <td>0.642362</td>\n",
       "      <td>0.642362</td>\n",
       "      <td>0.642362</td>\n",
       "      <td>0.642362</td>\n",
       "      <td>0.642362</td>\n",
       "      <td>0.642362</td>\n",
       "      <td>0.642362</td>\n",
       "      <td>0.644096</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.970925</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.769096</td>\n",
       "      <td>0.792535</td>\n",
       "      <td>0.792535</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.774303</td>\n",
       "      <td>0.816408</td>\n",
       "      <td>0.816408</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0.000558333</td>\n",
       "      <td>0.000558333</td>\n",
       "      <td>0.000558333</td>\n",
       "      <td>0.000558333</td>\n",
       "      <td>0.000558333</td>\n",
       "      <td>0.000558333</td>\n",
       "      <td>0.000558333</td>\n",
       "      <td>0.000558333</td>\n",
       "      <td>0.000558333</td>\n",
       "      <td>0.000558333</td>\n",
       "      <td>0.000558333</td>\n",
       "      <td>0.000558333</td>\n",
       "      <td>0.000558333</td>\n",
       "      <td>0.000558333</td>\n",
       "      <td>0.000558333</td>\n",
       "      <td>0.000558333</td>\n",
       "      <td>0.000558333</td>\n",
       "      <td>0.000558333</td>\n",
       "      <td>0.0046342</td>\n",
       "      <td>0.00875382</td>\n",
       "      <td>0.00875382</td>\n",
       "      <td>0.00719523</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0072285</td>\n",
       "      <td>0.0111027</td>\n",
       "      <td>0.0111027</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00945353</td>\n",
       "      <td>0.0087119</td>\n",
       "      <td>0.0087119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               0                            1  \\\n",
       "mean_fit_time                         0.00740051                   0.00460029   \n",
       "std_fit_time                          0.00215411                  0.000489882   \n",
       "mean_score_time                       0.00139995                   0.00100002   \n",
       "std_score_time                       0.000800037                  1.16801e-07   \n",
       "param_C                                    0.001                        0.001   \n",
       "param_gamma                                0.001                         0.01   \n",
       "params              {'C': 0.001, 'gamma': 0.001}  {'C': 0.001, 'gamma': 0.01}   \n",
       "split0_test_score                       0.637931                     0.637931   \n",
       "split1_test_score                       0.643478                     0.643478   \n",
       "split2_test_score                       0.643478                     0.643478   \n",
       "split3_test_score                       0.643478                     0.643478   \n",
       "split4_test_score                       0.643478                     0.643478   \n",
       "mean_test_score                         0.642361                     0.642361   \n",
       "std_test_score                        0.00222465                   0.00222465   \n",
       "rank_test_score                               12                           12   \n",
       "split0_train_score                      0.643478                     0.643478   \n",
       "split1_train_score                      0.642082                     0.642082   \n",
       "split2_train_score                      0.642082                     0.642082   \n",
       "split3_train_score                      0.642082                     0.642082   \n",
       "split4_train_score                      0.642082                     0.642082   \n",
       "mean_train_score                        0.642362                     0.642362   \n",
       "std_train_score                      0.000558333                  0.000558333   \n",
       "\n",
       "                                              2                         3  \\\n",
       "mean_fit_time                        0.00460029                0.00480037   \n",
       "std_fit_time                        0.000489882                0.00040009   \n",
       "mean_score_time                      0.00100002                0.00119996   \n",
       "std_score_time                      1.16801e-07               0.000400066   \n",
       "param_C                                   0.001                     0.001   \n",
       "param_gamma                                0.01                         1   \n",
       "params              {'C': 0.001, 'gamma': 0.01}  {'C': 0.001, 'gamma': 1}   \n",
       "split0_test_score                      0.637931                  0.637931   \n",
       "split1_test_score                      0.643478                  0.643478   \n",
       "split2_test_score                      0.643478                  0.643478   \n",
       "split3_test_score                      0.643478                  0.643478   \n",
       "split4_test_score                      0.643478                  0.643478   \n",
       "mean_test_score                        0.642361                  0.642361   \n",
       "std_test_score                       0.00222465                0.00222465   \n",
       "rank_test_score                              12                        12   \n",
       "split0_train_score                     0.643478                  0.643478   \n",
       "split1_train_score                     0.642082                  0.642082   \n",
       "split2_train_score                     0.642082                  0.642082   \n",
       "split3_train_score                     0.642082                  0.642082   \n",
       "split4_train_score                     0.642082                  0.642082   \n",
       "mean_train_score                       0.642362                  0.642362   \n",
       "std_train_score                     0.000558333               0.000558333   \n",
       "\n",
       "                                            4                           5  \\\n",
       "mean_fit_time                      0.00580034                   0.0126007   \n",
       "std_fit_time                      0.000399995                 0.000489824   \n",
       "mean_score_time                    0.00120001                  0.00300007   \n",
       "std_score_time                    0.000399923                 9.53674e-08   \n",
       "param_C                                 0.001                       0.001   \n",
       "param_gamma                                10                         100   \n",
       "params              {'C': 0.001, 'gamma': 10}  {'C': 0.001, 'gamma': 100}   \n",
       "split0_test_score                    0.637931                    0.637931   \n",
       "split1_test_score                    0.643478                    0.643478   \n",
       "split2_test_score                    0.643478                    0.643478   \n",
       "split3_test_score                    0.643478                    0.643478   \n",
       "split4_test_score                    0.643478                    0.643478   \n",
       "mean_test_score                      0.642361                    0.642361   \n",
       "std_test_score                     0.00222465                  0.00222465   \n",
       "rank_test_score                            12                          12   \n",
       "split0_train_score                   0.643478                    0.643478   \n",
       "split1_train_score                   0.642082                    0.642082   \n",
       "split2_train_score                   0.642082                    0.642082   \n",
       "split3_train_score                   0.642082                    0.642082   \n",
       "split4_train_score                   0.642082                    0.642082   \n",
       "mean_train_score                     0.642362                    0.642362   \n",
       "std_train_score                   0.000558333                 0.000558333   \n",
       "\n",
       "                                              6                           7  \\\n",
       "mean_fit_time                        0.00480042                  0.00480042   \n",
       "std_fit_time                        0.000400114                 0.000400114   \n",
       "mean_score_time                     0.000999928                  0.00120001   \n",
       "std_score_time                                0                 0.000400043   \n",
       "param_C                                    0.01                        0.01   \n",
       "param_gamma                               0.001                        0.01   \n",
       "params              {'C': 0.01, 'gamma': 0.001}  {'C': 0.01, 'gamma': 0.01}   \n",
       "split0_test_score                      0.637931                    0.637931   \n",
       "split1_test_score                      0.643478                    0.643478   \n",
       "split2_test_score                      0.643478                    0.643478   \n",
       "split3_test_score                      0.643478                    0.643478   \n",
       "split4_test_score                      0.643478                    0.643478   \n",
       "mean_test_score                        0.642361                    0.642361   \n",
       "std_test_score                       0.00222465                  0.00222465   \n",
       "rank_test_score                              12                          12   \n",
       "split0_train_score                     0.643478                    0.643478   \n",
       "split1_train_score                     0.642082                    0.642082   \n",
       "split2_train_score                     0.642082                    0.642082   \n",
       "split3_train_score                     0.642082                    0.642082   \n",
       "split4_train_score                     0.642082                    0.642082   \n",
       "mean_train_score                       0.642362                    0.642362   \n",
       "std_train_score                     0.000558333                 0.000558333   \n",
       "\n",
       "                                             8                        9  \\\n",
       "mean_fit_time                       0.00480022               0.00580034   \n",
       "std_fit_time                       0.000400019              0.000399995   \n",
       "mean_score_time                     0.00120015               0.00120006   \n",
       "std_score_time                     0.000399971              0.000400019   \n",
       "param_C                                   0.01                     0.01   \n",
       "param_gamma                               0.01                        1   \n",
       "params              {'C': 0.01, 'gamma': 0.01}  {'C': 0.01, 'gamma': 1}   \n",
       "split0_test_score                     0.637931                 0.637931   \n",
       "split1_test_score                     0.643478                 0.643478   \n",
       "split2_test_score                     0.643478                 0.643478   \n",
       "split3_test_score                     0.643478                 0.643478   \n",
       "split4_test_score                     0.643478                 0.643478   \n",
       "mean_test_score                       0.642361                 0.642361   \n",
       "std_test_score                      0.00222465               0.00222465   \n",
       "rank_test_score                             12                       12   \n",
       "split0_train_score                    0.643478                 0.643478   \n",
       "split1_train_score                    0.642082                 0.642082   \n",
       "split2_train_score                    0.642082                 0.642082   \n",
       "split3_train_score                    0.642082                 0.642082   \n",
       "split4_train_score                    0.642082                 0.642082   \n",
       "mean_train_score                      0.642362                 0.642362   \n",
       "std_train_score                    0.000558333              0.000558333   \n",
       "\n",
       "                                          10                         11  \\\n",
       "mean_fit_time                     0.00980053                  0.0132008   \n",
       "std_fit_time                     0.000399995                0.000399923   \n",
       "mean_score_time                   0.00140009                 0.00280004   \n",
       "std_score_time                   0.000489901                0.000399971   \n",
       "param_C                                 0.01                       0.01   \n",
       "param_gamma                               10                        100   \n",
       "params              {'C': 0.01, 'gamma': 10}  {'C': 0.01, 'gamma': 100}   \n",
       "split0_test_score                   0.637931                   0.637931   \n",
       "split1_test_score                   0.643478                   0.643478   \n",
       "split2_test_score                   0.643478                   0.643478   \n",
       "split3_test_score                   0.643478                   0.643478   \n",
       "split4_test_score                   0.643478                   0.643478   \n",
       "mean_test_score                     0.642361                   0.642361   \n",
       "std_test_score                    0.00222465                 0.00222465   \n",
       "rank_test_score                           12                         12   \n",
       "split0_train_score                  0.643478                   0.643478   \n",
       "split1_train_score                  0.642082                   0.642082   \n",
       "split2_train_score                  0.642082                   0.642082   \n",
       "split3_train_score                  0.642082                   0.642082   \n",
       "split4_train_score                  0.642082                   0.642082   \n",
       "mean_train_score                    0.642362                   0.642362   \n",
       "std_train_score                  0.000558333                0.000558333   \n",
       "\n",
       "                                             12                          13  \\\n",
       "mean_fit_time                        0.00460033                  0.00480027   \n",
       "std_fit_time                        0.000489921                 0.000400043   \n",
       "mean_score_time                     0.000999975                  0.00120006   \n",
       "std_score_time                      9.53674e-08                 0.000400019   \n",
       "param_C                                    0.01                        0.01   \n",
       "param_gamma                               0.001                        0.01   \n",
       "params              {'C': 0.01, 'gamma': 0.001}  {'C': 0.01, 'gamma': 0.01}   \n",
       "split0_test_score                      0.637931                    0.637931   \n",
       "split1_test_score                      0.643478                    0.643478   \n",
       "split2_test_score                      0.643478                    0.643478   \n",
       "split3_test_score                      0.643478                    0.643478   \n",
       "split4_test_score                      0.643478                    0.643478   \n",
       "mean_test_score                        0.642361                    0.642361   \n",
       "std_test_score                       0.00222465                  0.00222465   \n",
       "rank_test_score                              12                          12   \n",
       "split0_train_score                     0.643478                    0.643478   \n",
       "split1_train_score                     0.642082                    0.642082   \n",
       "split2_train_score                     0.642082                    0.642082   \n",
       "split3_train_score                     0.642082                    0.642082   \n",
       "split4_train_score                     0.642082                    0.642082   \n",
       "mean_train_score                       0.642362                    0.642362   \n",
       "std_train_score                     0.000558333                 0.000558333   \n",
       "\n",
       "                                            14                       15  \\\n",
       "mean_fit_time                       0.00500021               0.00580039   \n",
       "std_fit_time                       1.16801e-07              0.000400019   \n",
       "mean_score_time                     0.00100017               0.00140009   \n",
       "std_score_time                               0              0.000489999   \n",
       "param_C                                   0.01                     0.01   \n",
       "param_gamma                               0.01                        1   \n",
       "params              {'C': 0.01, 'gamma': 0.01}  {'C': 0.01, 'gamma': 1}   \n",
       "split0_test_score                     0.637931                 0.637931   \n",
       "split1_test_score                     0.643478                 0.643478   \n",
       "split2_test_score                     0.643478                 0.643478   \n",
       "split3_test_score                     0.643478                 0.643478   \n",
       "split4_test_score                     0.643478                 0.643478   \n",
       "mean_test_score                       0.642361                 0.642361   \n",
       "std_test_score                      0.00222465               0.00222465   \n",
       "rank_test_score                             12                       12   \n",
       "split0_train_score                    0.643478                 0.643478   \n",
       "split1_train_score                    0.642082                 0.642082   \n",
       "split2_train_score                    0.642082                 0.642082   \n",
       "split3_train_score                    0.642082                 0.642082   \n",
       "split4_train_score                    0.642082                 0.642082   \n",
       "mean_train_score                      0.642362                 0.642362   \n",
       "std_train_score                    0.000558333              0.000558333   \n",
       "\n",
       "                                          16                         17  \\\n",
       "mean_fit_time                      0.0102006                  0.0132007   \n",
       "std_fit_time                     0.000399995                0.000399971   \n",
       "mean_score_time                   0.00140004                  0.0032002   \n",
       "std_score_time                    0.00048994                0.000399876   \n",
       "param_C                                 0.01                       0.01   \n",
       "param_gamma                               10                        100   \n",
       "params              {'C': 0.01, 'gamma': 10}  {'C': 0.01, 'gamma': 100}   \n",
       "split0_test_score                   0.637931                   0.637931   \n",
       "split1_test_score                   0.643478                   0.643478   \n",
       "split2_test_score                   0.643478                   0.643478   \n",
       "split3_test_score                   0.643478                   0.643478   \n",
       "split4_test_score                   0.643478                   0.643478   \n",
       "mean_test_score                     0.642361                   0.642361   \n",
       "std_test_score                    0.00222465                 0.00222465   \n",
       "rank_test_score                           12                         12   \n",
       "split0_train_score                  0.643478                   0.643478   \n",
       "split1_train_score                  0.642082                   0.642082   \n",
       "split2_train_score                  0.642082                   0.642082   \n",
       "split3_train_score                  0.642082                   0.642082   \n",
       "split4_train_score                  0.642082                   0.642082   \n",
       "mean_train_score                    0.642362                   0.642362   \n",
       "std_train_score                  0.000558333                0.000558333   \n",
       "\n",
       "                                          18                       19  \\\n",
       "mean_fit_time                     0.00480032               0.00480037   \n",
       "std_fit_time                     0.000399947               0.00040009   \n",
       "mean_score_time                   0.00140009              0.000999975   \n",
       "std_score_time                   0.000489901              9.53674e-08   \n",
       "param_C                                    1                        1   \n",
       "param_gamma                            0.001                     0.01   \n",
       "params              {'C': 1, 'gamma': 0.001}  {'C': 1, 'gamma': 0.01}   \n",
       "split0_test_score                   0.637931                     0.75   \n",
       "split1_test_score                   0.643478                 0.782609   \n",
       "split2_test_score                   0.643478                 0.765217   \n",
       "split3_test_score                   0.643478                 0.686957   \n",
       "split4_test_score                   0.643478                 0.808696   \n",
       "mean_test_score                     0.642361                 0.758681   \n",
       "std_test_score                    0.00222465                0.0407987   \n",
       "rank_test_score                           12                        1   \n",
       "split0_train_score                  0.641304                 0.769565   \n",
       "split1_train_score                  0.644252                 0.774403   \n",
       "split2_train_score                  0.642082                 0.774403   \n",
       "split3_train_score                  0.652928                 0.780911   \n",
       "split4_train_score                  0.639913                 0.754881   \n",
       "mean_train_score                    0.644096                 0.770833   \n",
       "std_train_score                    0.0046342               0.00875382   \n",
       "\n",
       "                                         20                    21  \\\n",
       "mean_fit_time                    0.00400023            0.00720043   \n",
       "std_fit_time                    1.78416e-07            0.00040009   \n",
       "mean_score_time                  0.00100002             0.0012002   \n",
       "std_score_time                  1.16801e-07           0.000399947   \n",
       "param_C                                   1                     1   \n",
       "param_gamma                            0.01                     1   \n",
       "params              {'C': 1, 'gamma': 0.01}  {'C': 1, 'gamma': 1}   \n",
       "split0_test_score                      0.75               0.62069   \n",
       "split1_test_score                  0.782609              0.695652   \n",
       "split2_test_score                  0.765217              0.678261   \n",
       "split3_test_score                  0.686957              0.634783   \n",
       "split4_test_score                  0.808696              0.669565   \n",
       "mean_test_score                    0.758681              0.659722   \n",
       "std_test_score                    0.0407987             0.0278695   \n",
       "rank_test_score                           1                     9   \n",
       "split0_train_score                 0.769565              0.982609   \n",
       "split1_train_score                 0.774403              0.969631   \n",
       "split2_train_score                 0.774403              0.960954   \n",
       "split3_train_score                 0.780911              0.967462   \n",
       "split4_train_score                 0.754881               0.97397   \n",
       "mean_train_score                   0.770833              0.970925   \n",
       "std_train_score                  0.00875382            0.00719523   \n",
       "\n",
       "                                       22                      23  \\\n",
       "mean_fit_time                   0.0118007               0.0144008   \n",
       "std_fit_time                  0.000400162              0.00048994   \n",
       "mean_score_time                0.00160007              0.00300035   \n",
       "std_score_time                0.000489921             1.90735e-07   \n",
       "param_C                                 1                       1   \n",
       "param_gamma                            10                     100   \n",
       "params              {'C': 1, 'gamma': 10}  {'C': 1, 'gamma': 100}   \n",
       "split0_test_score                0.637931                0.637931   \n",
       "split1_test_score                0.643478                0.643478   \n",
       "split2_test_score                0.643478                0.643478   \n",
       "split3_test_score                0.643478                0.643478   \n",
       "split4_test_score                0.643478                0.643478   \n",
       "mean_test_score                  0.642361                0.642361   \n",
       "std_test_score                 0.00222465              0.00222465   \n",
       "rank_test_score                        12                      12   \n",
       "split0_train_score                      1                       1   \n",
       "split1_train_score                      1                       1   \n",
       "split2_train_score                      1                       1   \n",
       "split3_train_score                      1                       1   \n",
       "split4_train_score                      1                       1   \n",
       "mean_train_score                        1                       1   \n",
       "std_train_score                         0                       0   \n",
       "\n",
       "                                           24                        25  \\\n",
       "mean_fit_time                      0.00480018                0.00480042   \n",
       "std_fit_time                      0.000399995               0.000400114   \n",
       "mean_score_time                    0.00100012                0.00100002   \n",
       "std_score_time                    1.78416e-07               1.16801e-07   \n",
       "param_C                                    10                        10   \n",
       "param_gamma                             0.001                      0.01   \n",
       "params              {'C': 10, 'gamma': 0.001}  {'C': 10, 'gamma': 0.01}   \n",
       "split0_test_score                        0.75                      0.75   \n",
       "split1_test_score                    0.782609                  0.773913   \n",
       "split2_test_score                    0.756522                  0.721739   \n",
       "split3_test_score                    0.695652                  0.686957   \n",
       "split4_test_score                    0.808696                  0.791304   \n",
       "mean_test_score                      0.758681                  0.744792   \n",
       "std_test_score                      0.0377225                 0.0371569   \n",
       "rank_test_score                             1                         7   \n",
       "split0_train_score                   0.767391                  0.793478   \n",
       "split1_train_score                   0.765727                  0.791757   \n",
       "split2_train_score                   0.772234                  0.789588   \n",
       "split3_train_score                   0.780911                   0.81128   \n",
       "split4_train_score                   0.759219                  0.776573   \n",
       "mean_train_score                     0.769096                  0.792535   \n",
       "std_train_score                     0.0072285                 0.0111027   \n",
       "\n",
       "                                          26                     27  \\\n",
       "mean_fit_time                     0.00480032             0.00860062   \n",
       "std_fit_time                     0.000400066            0.000489901   \n",
       "mean_score_time                   0.00100002             0.00140004   \n",
       "std_score_time                   1.90735e-07             0.00048994   \n",
       "param_C                                   10                     10   \n",
       "param_gamma                             0.01                      1   \n",
       "params              {'C': 10, 'gamma': 0.01}  {'C': 10, 'gamma': 1}   \n",
       "split0_test_score                       0.75                0.62069   \n",
       "split1_test_score                   0.773913               0.713043   \n",
       "split2_test_score                   0.721739               0.686957   \n",
       "split3_test_score                   0.686957               0.608696   \n",
       "split4_test_score                   0.791304               0.669565   \n",
       "mean_test_score                     0.744792               0.659722   \n",
       "std_test_score                     0.0371569              0.0395188   \n",
       "rank_test_score                            7                      9   \n",
       "split0_train_score                  0.793478                      1   \n",
       "split1_train_score                  0.791757                      1   \n",
       "split2_train_score                  0.789588                      1   \n",
       "split3_train_score                   0.81128                      1   \n",
       "split4_train_score                  0.776573                      1   \n",
       "mean_train_score                    0.792535                      1   \n",
       "std_train_score                    0.0111027                      0   \n",
       "\n",
       "                                        28                       29  \\\n",
       "mean_fit_time                    0.0154008                0.0158009   \n",
       "std_fit_time                   0.000489921              0.000399923   \n",
       "mean_score_time                  0.0012001               0.00300016   \n",
       "std_score_time                 0.000399995              1.90735e-07   \n",
       "param_C                                 10                       10   \n",
       "param_gamma                             10                      100   \n",
       "params              {'C': 10, 'gamma': 10}  {'C': 10, 'gamma': 100}   \n",
       "split0_test_score                 0.637931                 0.637931   \n",
       "split1_test_score                 0.634783                 0.643478   \n",
       "split2_test_score                 0.643478                 0.643478   \n",
       "split3_test_score                 0.643478                 0.643478   \n",
       "split4_test_score                 0.643478                 0.643478   \n",
       "mean_test_score                   0.640625                 0.642361   \n",
       "std_test_score                  0.00362665               0.00222465   \n",
       "rank_test_score                         35                       12   \n",
       "split0_train_score                       1                        1   \n",
       "split1_train_score                       1                        1   \n",
       "split2_train_score                       1                        1   \n",
       "split3_train_score                       1                        1   \n",
       "split4_train_score                       1                        1   \n",
       "mean_train_score                         1                        1   \n",
       "std_train_score                          0                        0   \n",
       "\n",
       "                                            30                         31  \\\n",
       "mean_fit_time                       0.00500021                 0.00800047   \n",
       "std_fit_time                       1.16801e-07                 0.00063241   \n",
       "mean_score_time                     0.00100012                0.000800037   \n",
       "std_score_time                     9.53674e-08                0.000400019   \n",
       "param_C                                    100                        100   \n",
       "param_gamma                              0.001                       0.01   \n",
       "params              {'C': 100, 'gamma': 0.001}  {'C': 100, 'gamma': 0.01}   \n",
       "split0_test_score                     0.758621                       0.75   \n",
       "split1_test_score                     0.791304                        0.8   \n",
       "split2_test_score                      0.73913                   0.756522   \n",
       "split3_test_score                     0.695652                    0.66087   \n",
       "split4_test_score                          0.8                   0.765217   \n",
       "mean_test_score                       0.756944                   0.746528   \n",
       "std_test_score                       0.0376801                  0.0461291   \n",
       "rank_test_score                              4                          5   \n",
       "split0_train_score                    0.769565                   0.819565   \n",
       "split1_train_score                    0.772234                   0.800434   \n",
       "split2_train_score                    0.774403                   0.819957   \n",
       "split3_train_score                    0.791757                   0.826464   \n",
       "split4_train_score                    0.763557                   0.815618   \n",
       "mean_train_score                      0.774303                   0.816408   \n",
       "std_train_score                     0.00945353                  0.0087119   \n",
       "\n",
       "                                           32                      33  \\\n",
       "mean_fit_time                      0.00800042              0.00800037   \n",
       "std_fit_time                       0.00063241                       0   \n",
       "mean_score_time                    0.00100007              0.00180016   \n",
       "std_score_time                    1.16801e-07             0.000400114   \n",
       "param_C                                   100                     100   \n",
       "param_gamma                              0.01                       1   \n",
       "params              {'C': 100, 'gamma': 0.01}  {'C': 100, 'gamma': 1}   \n",
       "split0_test_score                        0.75                 0.62069   \n",
       "split1_test_score                         0.8                0.713043   \n",
       "split2_test_score                    0.756522                0.686957   \n",
       "split3_test_score                     0.66087                0.591304   \n",
       "split4_test_score                    0.765217                0.669565   \n",
       "mean_test_score                      0.746528                 0.65625   \n",
       "std_test_score                      0.0461291               0.0443217   \n",
       "rank_test_score                             5                      11   \n",
       "split0_train_score                   0.819565                       1   \n",
       "split1_train_score                   0.800434                       1   \n",
       "split2_train_score                   0.819957                       1   \n",
       "split3_train_score                   0.826464                       1   \n",
       "split4_train_score                   0.815618                       1   \n",
       "mean_train_score                     0.816408                       1   \n",
       "std_train_score                     0.0087119                       0   \n",
       "\n",
       "                                         34                        35  \n",
       "mean_fit_time                     0.0146009                  0.016401  \n",
       "std_fit_time                     0.00048994                0.00101995  \n",
       "mean_score_time                  0.00180006                0.00300002  \n",
       "std_score_time                  0.000400066                         0  \n",
       "param_C                                 100                       100  \n",
       "param_gamma                              10                       100  \n",
       "params              {'C': 100, 'gamma': 10}  {'C': 100, 'gamma': 100}  \n",
       "split0_test_score                  0.637931                  0.637931  \n",
       "split1_test_score                  0.634783                  0.643478  \n",
       "split2_test_score                  0.643478                  0.643478  \n",
       "split3_test_score                  0.643478                  0.643478  \n",
       "split4_test_score                  0.643478                  0.643478  \n",
       "mean_test_score                    0.640625                  0.642361  \n",
       "std_test_score                   0.00362665                0.00222465  \n",
       "rank_test_score                          35                        12  \n",
       "split0_train_score                        1                         1  \n",
       "split1_train_score                        1                         1  \n",
       "split2_train_score                        1                         1  \n",
       "split3_train_score                        1                         1  \n",
       "split4_train_score                        1                         1  \n",
       "mean_train_score                          1                         1  \n",
       "std_train_score                           0                         0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#교차검증 시각화\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "display(np.transpose(results))\n",
    "\n",
    "#cv_results_ = 그리드 서치의 결과가 담긴 딕셔너리\n",
    "#행하나가 특정 매개변수 설정에 대응된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n",
      "C:\\Users\\a\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PolyCollection at 0x1276e128>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#2차원 그리드(C와 gamma)이므로 히트맵으로 시각화 할 수 있다.\n",
    "\n",
    "#교차 검증의 평균을 뽑아서 C와 gamma 축에 맞도록 배열 차원을 바꿔준다.\n",
    "import mglearn\n",
    "scores = np.array(results.mean_test_score).reshape(6, 6)\n",
    "\n",
    "mglearn.tools.heatmap(scores, xlabel = 'gamma', xticklabels = param_grid['gamma'],\n",
    "                     ylabel = 'C', yticklabels = param_grid['C'], cmap = 'viridis')\n",
    "\n",
    "#SVC가 매개변수 설정에 민감함을 알 수 있다. -> 매개변수 설정이 중요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
